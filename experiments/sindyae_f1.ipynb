{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2da25bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\Dioporco\\Desktop\\Cognitive Science UOS\\4-D\\SINDy_Autoencoder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# path che vuoi usare come root\n",
    "ROOT = Path(\"C:/Users/Dioporco/Desktop/Cognitive Science UOS/4-D/SINDy_Autoencoder\")\n",
    "\n",
    "os.chdir(ROOT)       # cambia la working directory\n",
    "sys.path.append(str(ROOT))   # cos√¨ puoi importare model.py, trainer.py, ecc.\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c9346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Distance       Speed  Throttle  Brake     nGear           RPM            X  \\\n",
      "0  0.000000  252.524998     100.0    0.0  6.000000  10635.925357 -1771.696849   \n",
      "1  1.405556  252.774999     100.0    0.0  6.000000  10580.175169 -1763.191162   \n",
      "2  2.813889  253.062112     100.0    0.0  6.012422  10533.118012 -1754.669267   \n",
      "3  4.247222  253.683230     100.0    0.0  6.136646  10564.298137 -1746.001490   \n",
      "4  5.680556  254.304348     100.0    0.0  6.260870  10595.478261 -1737.333713   \n",
      "\n",
      "             Y            Z     t  lap  \n",
      "0  1189.633010  1963.202931  0.00    0  \n",
      "1  1201.007901  1963.261456  0.02    0  \n",
      "2  1212.381744  1963.322393  0.04    0  \n",
      "3  1223.746160  1963.405044  0.06    0  \n",
      "4  1235.110575  1963.487695  0.08    0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4526 entries, 0 to 4525\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Distance  4526 non-null   float64\n",
      " 1   Speed     4526 non-null   float64\n",
      " 2   Throttle  4526 non-null   float64\n",
      " 3   Brake     4526 non-null   float64\n",
      " 4   nGear     4526 non-null   float64\n",
      " 5   RPM       4526 non-null   float64\n",
      " 6   X         4526 non-null   float64\n",
      " 7   Y         4526 non-null   float64\n",
      " 8   Z         4526 non-null   float64\n",
      " 9   t         4526 non-null   float64\n",
      " 10  lap       4526 non-null   int64  \n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 389.1 KB\n",
      "None\n",
      "(4526, 9)\n",
      "(4526,)\n",
      "(4526,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "datadir = Path(\"dataset_2022_silverstone_ham\")\n",
    "\n",
    "X = np.load(datadir/\"X.npy\")\n",
    "t = np.load(datadir/\"t.npy\")\n",
    "lap_idx = np.load(datadir/\"lap_indices.npy\")\n",
    "\n",
    "with open(datadir/\"metadata.json\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "state_cols = meta[\"state_cols\"]\n",
    "dt = meta[\"dt\"]\n",
    "\n",
    "scaler = json.load(open(datadir / \"scaler.json\"))\n",
    "\n",
    "X_mean = np.array(scaler[\"X_mean\"])\n",
    "X_scale = np.array(scaler[\"X_scale\"])\n",
    "\n",
    "X_phys = X * X_scale + X_mean\n",
    "df_phys = pd.DataFrame(X_phys, columns=state_cols)\n",
    "df_phys[\"t\"] = t\n",
    "df_phys[\"lap\"] = lap_idx\n",
    "\n",
    "df_phys.to_csv(datadir / \"dataset_physical_units.csv\", index=False)\n",
    "print(df_phys.head())\n",
    "print(df_phys.info())\n",
    "print(X_phys.shape)\n",
    "print(t.shape)\n",
    "print(lap_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6af07a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# F1_SINDyAE Notebook - Setup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.model import SINDy_Autoencoder, TimeSeriesDataset   # your model classes\n",
    "from src.trainer import Trainer_SINDyAE                      # your trainer\n",
    "from utils.diff_methods import compute_derivatives             # your derivative util\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af6136d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N samples: 4526 | x_dim: 9\n",
      "X_seq shape: (217, 200, 9)\n"
     ]
    }
   ],
   "source": [
    "# Build fixed-length time windows from the long time series\n",
    "# Result: X_seq with shape (n_traj, T_window, n_state)\n",
    "\n",
    "T_window = 200   # sequence length (es. 200 step)\n",
    "stride = 20      # shift from one window to the following one\n",
    "\n",
    "N, x_dim = X.shape\n",
    "print(\"N samples:\", N, \"| x_dim:\", x_dim)\n",
    "\n",
    "windows = []\n",
    "for start in range(0, N - T_window + 1, stride):\n",
    "    end = start + T_window\n",
    "    windows.append(X[start:end, :])\n",
    "\n",
    "X_seq = np.stack(windows, axis=0)   # (n_traj, T_window, x_dim)\n",
    "print(\"X_seq shape:\", X_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c84ee33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINDy_Autoencoder(\n",
      "  (autoencoder): Autoencoder(\n",
      "    (encoder): Encoder(\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=9, out_features=128, bias=True)\n",
      "        (1): Sigmoid()\n",
      "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (3): Sigmoid()\n",
      "        (4): Linear(in_features=64, out_features=3, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (decoder): Decoder(\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=3, out_features=64, bias=True)\n",
      "        (1): Sigmoid()\n",
      "        (2): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (3): Sigmoid()\n",
      "        (4): Linear(in_features=128, out_features=9, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sindy): SINDy_layer()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model hyperparameters (puoi adattare ai tuoi)\n",
    "\n",
    "x_dim = X_seq.shape[-1]   # number of state variables (Distance, Speed, Throttle, ...)\n",
    "z_dim = 3                 # es: 3 latent dimensions (you choose)\n",
    "\n",
    "enc_hidden = (128, 64)    # encoder MLP sizes\n",
    "dec_hidden = (64, 128)    # decoder MLP sizes\n",
    "poly_order = 3            # polynomial library for SINDy\n",
    "include_bias = True\n",
    "\n",
    "model = SINDy_Autoencoder(\n",
    "    x_dim=x_dim,\n",
    "    z_dim=z_dim,\n",
    "    enc_hidden=enc_hidden,\n",
    "    dec_hidden=dec_hidden,\n",
    "    poly_order=poly_order,\n",
    "    include_bias=include_bias,\n",
    ").to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59d64b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] Using device: cpu\n",
      "[INIT] Model first param device: cpu\n",
      "Trainer ready.\n"
     ]
    }
   ],
   "source": [
    "# Trainer hyperparameters\n",
    "\n",
    "trainer = Trainer_SINDyAE(\n",
    "    model=model,\n",
    "    dt=dt,\n",
    "    diff_method=\"finite\",      # o il tuo metodo (dipende da diff_methods.py)\n",
    "    diff_kwargs={},\n",
    "\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    device=device,\n",
    "\n",
    "    lambda_recon=1.0,\n",
    "    lambda_dx=1e-3,\n",
    "    lambda_dz=1e-3,\n",
    "\n",
    "    threshold=0.1,\n",
    "    threshold_freq=50,\n",
    "    lr=1e-3,\n",
    ")\n",
    "\n",
    "print(\"Trainer ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the F1 sequences\n",
    "\n",
    "n_epochs = 500\n",
    "log_every = 50\n",
    "\n",
    "trainer.fit(\n",
    "    X_seq,\n",
    "    n_epochs=n_epochs,\n",
    "    log_every=log_every,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect training history\n",
    "\n",
    "hist = pd.DataFrame(trainer.history_loss)\n",
    "display(hist.tail())\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(hist[\"loss\"], label=\"Total loss\")\n",
    "plt.plot(hist[\"L_recon\"], label=\"Recon\")\n",
    "plt.plot(hist[\"L_dx\"], label=\"L_dx\")\n",
    "plt.plot(hist[\"L_dz\"], label=\"L_dz\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss (log)\")\n",
    "plt.legend()\n",
    "plt.title(\"Training losses\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SINDy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
